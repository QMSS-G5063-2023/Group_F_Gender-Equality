---
title: "Gender Inequality in United States"
author: "Lestary Barany, Fayren Chaerunnissa, Manickamalar Kayalvizhi Pillay"
date: "2023-05-02"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: true
    number_sections: true
    theme: united
    highlight: textmate
    toc_depth: 2
    keep_md: true
    fig_caption: true
    self_contained: false
    css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Gender equality is an ongoing issue in the United States, particularly when it comes to employment and income. Despite progress in recent years, there is still a significant gap between men and women in terms of pay and job opportunities. Understanding the factors that contribute to this inequality is crucial for creating positive change. This project brings together data from various sources to help us better understand the geospatial condition of gender inequality, how it has evolved over time, and case studies in two industries.

```{r, echo = FALSE,  include=FALSE, message = FALSE}
# Load the required packages
library(tidyr)
library(dplyr)
library(ggplot2)
library(ggthemes)
library(plotly)
library(igraph)
```

# Population and Employment by States
The gender-based unemployment data was obtained from the US Bureau of Labour Statistics in the following link https://www.bls.gov/lau/ex14tables.htm 
We are solely focusing on unemployment data from 2022 for each US state.

```{r, echo = FALSE, include=FALSE, message = FALSE}
# INTRODUCTION
# setwd("C:/Users/ASUS/Desktop/dataviz final data")

# Load required packages
library(readxl)
library(dplyr)
library(leaflet)
library(tidyr)

# Read XLSX file using read_excel function from readxl package
data <- read_excel("ptable14afull2022.xlsx", sheet = "State_Gender")

# Write data to CSV file using write.csv function
write.csv(data, file = "state_unemployment.csv", row.names = FALSE)

# Load dataset
data <- read.csv("state_unemployment.csv")

df_select <- select(data, State, Population.Group, Unemployment.rate)

# Pivot the data to have male and female unemployment rates as separate columns
unemployment_rate <- df_select %>% pivot_wider(names_from = Population.Group, values_from = Unemployment.rate)

## Based on the dataset called unemployment_rate (which contains State, Total, Men, Women), create a leaflet map of the United States showing unemployment rates for each state.

```{r, echo = FALSE, include=FALSE, message = FALSE}
# Load required libraries
library(leaflet)
library(sf)
library(dplyr)

# Read the geojson files
us_outline <- st_read("gz_2010_us_outline_500k.json")
us_states <- st_read("gz_2010_us_040_00_500k.json")

# Merge unemployment_rate with us_states
us_states_merged <- left_join(us_states, unemployment_rate, by = c("NAME" = "State"))

# Create a color palette for unemployment rates
total_unemployment_palette <- colorQuantile(palette = "YlOrRd", domain = us_states_merged$Total, n = 5)
unemployment_breaks <- seq(0.0, 0.10, by = 0.02)

# Define the bounding box corners
southwest <- c(19, -180) # Latitude, longitude for the southwest corner
northeast <- c(73, -63)  # Latitude, longitude for the northeast corner

# Create a leaflet map
map <- leaflet(us_states_merged) %>%
  setView(-98.5795, 39.8283, zoom = 4) %>%
  addProviderTiles(providers$Stamen.TonerLite) %>%
  addPolygons(
    fillColor = ~total_unemployment_palette(Total),
    fillOpacity = 0.8,
    color = "#000000",
    weight = 1,
    popup = ~paste(NAME, "<br>Total Unemployment:", Total, "%",
                   "<br>Male: ", Men, "%",
                   "<br>Female: ", Women, "%"),
  )


```
This interactive map depicts the unemployment rates of each US state, with separate color coding for total unemployment and unemployment by gender. Darker shades indicate higher unemployment rates, while lighter shades correspond to lower unemployment rates. By analyzing the map, it becomes apparent that many states in the West Coast, including California, Oregon, Washington State, and Nevada, have higher unemployment rates compared to the Midwest. Additionally, some states in the Northeast, such as New York, Connecticut, and Pennsylvania, also display higher unemployment rates. The map effectively highlights geographic patterns of unemployment across the US and provides insights into disparities among different regions and demographic groups.

```{r, echo = FALSE, include=FALSE, message = FALSE}
## Create gender layers

# Load required libraries
library(leaflet)
library(sf)
library(dplyr)

# MALE LAYER

# Create a color palette for male unemployment rates
male_unemployment_palette <- colorQuantile(palette = "Blues", domain = us_states_merged$Men, n = 5)

# Create a male unemployment layer
male_layer <- map %>%
  addTiles(options = providerTileOptions(minZoom = 3, maxZoom = 10)) %>%
  addPolygons(
    data = us_states_merged,
    fillColor = ~male_unemployment_palette(Men),
    fillOpacity = 0.8,
    color = "#000000",
    weight = 1,
    popup = ~paste(NAME, "<br>Male Unemployment:", Men, "%"),
  )
```


```{r, echo = FALSE, include=FALSE, message = FALSE}
# Create a color palette for female unemployment rates
female_unemployment_palette <- colorQuantile(palette = "PuRd", domain = us_states_merged$Women, n = 5)

# Create a female unemployment layer
female_layer <- map %>%
  addTiles(options = providerTileOptions(minZoom = 3, maxZoom = 10)) %>%
  addPolygons(
    data = us_states_merged,
    fillColor = ~female_unemployment_palette(Women),
    fillOpacity = 0.8,
    color = "#000000",
    weight = 1,
    popup = ~paste(NAME, "<br>Female Unemployment:", Women, "%"),
  )

```

```{r, echo = FALSE, include=FALSE, message = FALSE}
# Load required libraries
library(leaflet)
library(sf)
library(dplyr)

# Read the geojson files
us_outline <- st_read("gz_2010_us_outline_500k.json")
us_states <- st_read("gz_2010_us_040_00_500k.json")

# Merge unemployment_rate with us_states
us_states_merged <- left_join(us_states, unemployment_rate, by = c("NAME" = "State"))

# Define the bounding box corners
southwest <- c(19, -180) # Latitude, longitude for the southwest corner
northeast <- c(73, -63)  # Latitude, longitude for the northeast corner

# Create a color palette for unemployment rates
total_unemployment_palette <- colorQuantile(palette = "YlOrRd", domain = us_states_merged$Total, n = 5)
male_unemployment_palette <- colorQuantile(palette = "Blues", domain = us_states_merged$Men, n = 5)
female_unemployment_palette <- colorQuantile(palette = "PuRd", domain = us_states_merged$Women, n = 5)
  
```

```{r, echo=FALSE}
# Create a basic leaflet map
map <- leaflet() %>%
  setView(-98.5795, 39.8283, zoom = 4) %>%
  addProviderTiles(providers$Stamen.TonerLite) # Base groups = background layer

# Add all layers to the map
map %>%
  addPolygons(
    data = us_states_merged,
    group = "Total Unemployment",
    fillColor = ~total_unemployment_palette(Total),
    fillOpacity = 0.8,
    color = "#000000",
    weight = 1,
    popup = ~paste(NAME, "<br>Total Unemployment:", Total, "%",
                   "<br>Male: ", Men, "%",
                   "<br>Female: ", Women, "%")
  ) %>%
  addPolygons(
    data = us_states_merged,
    group = "Male Unemployment",
    fillColor = ~male_unemployment_palette(Men),
    fillOpacity = 0.8,
    color = "#000000",
    weight = 1,
    popup = ~paste(NAME, "<br>Male Unemployment:", Men, "%")
  ) %>%
  addPolygons(
    data = us_states_merged,
    group = "Female Unemployment",
    fillColor = ~female_unemployment_palette(Women),
    fillOpacity = 0.8,
    color = "#000000",
    weight = 1,
    popup = ~paste(NAME, "<br>Female Unemployment:", Women, "%")
  ) %>%
  # Add layer controls to switch between layers
  addLayersControl(
    overlayGroups = c("Total Unemployment", "Male Unemployment", "Female Unemployment"),
    options = layersControlOptions(collapsed = FALSE)
  )
```

Based on the map, we can visually interpret that for both genders, there is relatively higher unemployment in the West Coast and some states in the Northeast, compared to the Midwest. For instance, for male unemployment, there is high unemployment in states like Nevada, Washington and California. Interestingly, similar patterns can be seen for female unemployment. Perhaps there aren't pronounced gender differences in unemployment in many states in the US in 2022.

# Gender Gap Trends Over Time in United States

In the United States, female employment rates remain consistently lower than male employment rates, with a gap of around 20%. Furthermore, female workers receive significantly lower pay than their male counterparts, with the gap in income also hovering around 20%. While this gap has nominally decreased over time, it remains a persistent issue, with a variety of factors contributing to this disparity. 

```{r, echo = FALSE, include=FALSE, message = FALSE}
# Set the file path
file_path <- "openwatchgender.csv"

# Read the file using read.csv() function
data <- read.csv(file_path, header = TRUE)
```

```{r,echo = FALSE, include=FALSE, message = FALSE}
# Filter the data for the indicator names 'Employment to Population Ratio (% of population), female' and 'Employment to Population Ratio (% of population), male'
employment_data <- subset(data, indicator_name %in% c("Employment to Population Ratio (% of population), female", "Employment to Population Ratio (% of population), male"))

# Convert the data to a long format
employment_data_long <- gather(employment_data, year, employment, X2000:X2016, na.rm = TRUE)

# Add a 'year' column by extracting the year from the 'year' column
employment_data_long$year <- as.integer(substr(employment_data_long$year, 2, 5))

# Convert the 'employment' column to numeric
employment_data_long$employment <- as.numeric(employment_data_long$employment)

# Remove any missing values
employment_data_long <- na.omit(employment_data_long)

# Filter the data for the United States
employment_data_us <- filter(employment_data_long, country_name == "United States")
```

```{r, echo=FALSE}
# Create the plot
ggplot(employment_data_us, aes(x = year, y = employment, color = indicator_name)) + 
  geom_line(linewidth = 1) +
  scale_color_manual(values = c("#F06292", "#008FD5"), name = "Gender", labels = c("Female", "Male")) +
  labs(title = "Employment in the United States",
       x = "Year",
       y = "Employment (% of population)") +
  theme_economist() +
   theme(plot.title = element_text(size = 16, hjust = 0.5),
        axis.title = element_text(size = 11),
        legend.title = element_text(size = 11),
        legend.text = element_text(size = 11),
        axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0)))
```

```{r, echo = FALSE, include=FALSE, message = FALSE}
earning <- read.csv("income-by-gender.csv")

# Rename Measure.Values column to income
names(earning)[names(earning) == "Measure.Values"] <- "income"

# Rename Measures.Names column to Gender
names(earning)[names(earning) == "Measure.Names"] <- "Gender"

earning <- earning %>% 
  filter(Gender %in% c("Total Men", "Total Women")) %>% 
  mutate(Income = as.numeric(gsub("[^0-9]", "", Income)))
```

```{r, echo=FALSE}
ggplot(data = earning, aes(x = Year, y = Income, color = Gender)) +
  geom_line(linewidth = 1) +
  scale_color_manual(values = c("#008FD5", "#F06292"), name = "Gender", labels = c("Male", "Female")) +
  labs(title = "Income in the United States",
       x = "Year",
       y = "Income") +
  theme_economist() +
  theme(plot.title = element_text(size = 16, hjust = 0.5),
        axis.title = element_text(size = 11),
        legend.title = element_text(size = 11),
        legend.text = element_text(size = 11),
        axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0)))
```

# Breaking the Glass Ceiling: Top 10 Occupations for Women in the United States

While it is true that the top occupations for women in the United States are primarily in the services industry, it is important to note that a significant portion of these jobs are low-skilled or involve repetitive tasks. While these jobs are necessary for our economy and provide important services to communities, they often do not offer the same level of job security or opportunities for career growth as higher-skilled occupations. It is important to work towards creating a more equal job market where women have access to a wider range of employment opportunities, including those that offer more skill development and higher pay. 

```{r, echo = FALSE, include=FALSE, message = FALSE}
occupations <- read.csv("top-10-women-occupations.csv")

# Sort the data frame by rank
occupations <- occupations[order(-occupations$Rank),]

# Remove non-numeric characters from the Worker column
occupations$Worker <- as.numeric(gsub("[^0-9]+", "", occupations$Worker))
```

```{r, echo=FALSE}
# Create the vertical bar chart
ggplot(occupations, aes(x = reorder(Occupation, -Worker), y = Worker/1000)) +
  geom_col(fill = "#F06292") +
  labs(title = "Top 10 Women Occupations", x = "Occupations", y = "Number of Workers (in 1000)") +
  theme_economist() +
  coord_flip() +
   theme(plot.title = element_text(size = 14, hjust = 0.5),
        axis.title = element_text(size = 11),
        legend.title = element_text(size = 11),
        legend.text = element_text(size = 11),
        axis.title.x = element_text(margin = margin(t = 1, r = 10, b = 1, l = 0)),
        axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0)))
```

# Case Study 1: Lazega Law Firm in United States

```{r, echo = FALSE, include=FALSE, message = FALSE}
trends <- read.csv("Lazega-Atts.csv")
advice <- read.csv("Lazega-Advice-Net-B_20-_20Sheet_201+_2_.csv")

# create loop to count frequencies of 1s per ID (try as cannot merge otherwise)
interactions <- numeric()
for (i in 1:(nrow(advice)-1)) {
  str_i <- as.character(i)
  new <- sum(advice[str_i, -1])
  interactions <- c(interactions, new)
}

# create loop to create df
numbers <- 1:70

advice_df <- data.frame(
  ID = numbers,
  Interactions = interactions
)

# join by: `df1.col1 == df2.index`
Advice_interactions <- inner_join(trends, advice_df, by = 'ID')
```

```{r, echo=FALSE, warning=FALSE}
fig <- plot_ly(x = Advice_interactions$practice, y = Advice_interactions$Interactions, color = factor(Advice_interactions$gender) , type = "box")
fig <- layout(fig, xaxis = list(
  ticktext = c("Litigation", "Corporate"),
  title = "No. of interactions by practice, split by gender (1=man,2=woman)"
))

fig
```
A box plot of the number of interactions each of node in the network. This is split on two levels -- First, it is split by practice (1 = Litigation and 2 = Corporate). This is then further split by men and women (1=man, 2 =woman).

```{r, echo = FALSE, include=FALSE, message = FALSE}
d=read.csv(file ='Lazega-Advice-Net-B_20-_20Sheet_201+_2_.csv')
m=as.matrix(d)
dmg=graph.adjacency(m)

### Girvan-Newman partitioning ---

gn = edge.betweenness.community (dmg, directed = TRUE)
```

```{r, echo = FALSE, message = FALSE}
memb = data.frame(gn$membership)

summary(memb)
```

```{r, echo = FALSE, include=FALSE, message = FALSE}
### Random walk partitioning ---

walk = walktrap.community(dmg)

head(walk)
```

```{r, echo = FALSE, include = FALSE, message = FALSE}
walk.memb = data.frame(walk$membership)

## making a dataframe of partitioning ---
dd <-data.frame(name = V(dmg)$name)
cb1 <- cbind(dd, memb, walk.memb)
head(cb1)

# Visualised network in R using Random Walk communities as they were more sensible that G-N.

edges = get.edgelist(dmg)

attributesd=read.csv(file ='Lazega-Atts.csv')


```

```{r, echo=FALSE}
# Second part has two plots created: a) colouring by membership and b) colouring by gender
plot(walk, dmg, col=factor(walk$membership))
```
The above social network graph has grouped the Lazega nodes using the Random Walk algorithm method to classify groups. Thereafter, the nodes are coloured by gender. As we can see from the graph, the number of women are materially fewer than the men.

# Case Study 2: Differences in gender representation in Hollywood
We conducted text analysis of plot descriptions of movies to compare the use of words between American Hollywood films that have good and bad female representation. We used the Bechdel test as a measure of female representation, which looks at whether a movie has at least two named female characters who talk to each other about something other than a man. By analyzing the plot descriptions, we aimed to understand how movies with good and bad female representation differ in the words they use. Even though the Bechdel test isn't the sole indicator of female representation in films, this analysis can provide insights into how women are portrayed in movies and how their representation can impact the way we perceive and value women in society.

The datasets were obtained from a study conducted by FiveThirtyEight on Hollywood's gender bias. The datasets can be downloaded from the following Github repository https://github.com/rfordatascience/tidytuesday/tree/master/data/2021/2021-03-09  


```{r, echo = FALSE, include=FALSE, message = FALSE}
# Import Data
raw_bechdel <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-09/raw_bechdel.csv')
movies <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-09/movies.csv')

data <- merge(raw_bechdel, movies, by = "title")

# Filter out 0 in ratings
library(dplyr)

data_filtered <- data %>%
  filter(rating != 0)
```
 
We chose 500 movies that pass the Bechdel Test and compare with 500 movies that failed the Bechdel test. We will analyse the text from "plot". We use the cleaning functions to remove unnecessary words (stop words), syntax, punctuation, numbers, white space, etc. We also creates a document-term-matrix, and provided word clouds of the most frequent words among the movies that pass and fail the Bechdel test.


```{r, echo = FALSE, include=FALSE, message = FALSE}
library(dplyr)
library(wordcloud2)
library(tidytext)
library(stringr)
library(plotrix)
library(wordcloud)
library(tm)

# Select the 500 movies that pass the Bechdel Test and 500 movies that failed the Bechdel test
pass <- data_filtered %>% 
  arrange(desc(binary)) %>% 
  head(500)

fail <- data_filtered %>% 
  arrange(binary) %>% 
  head(500)

# Combine pass and fail into one dataframe
all_bechdel <- bind_rows(pass,fail)

# Clean the text for PASS
clean_text_pass <- pass %>% 
  select(plot) %>% 
  unnest_tokens(word, plot) %>% 
  mutate(word = str_replace_all(word, "[^[:alnum:]']", "")) %>% 
  filter(!word %in% stop_words$word) %>% 
  filter(!str_detect(word, "^\\d+$")) %>% 
  mutate(word = str_to_lower(word)) %>% 
  count(word, sort = TRUE) %>% 
  slice_head(n = 100)

# Create a Document-Term-Matrix
movie_dtm <- DocumentTermMatrix(pass)

# Define a custom color palette of different shades of pink
pink_palette <- colorRampPalette(c("#FFC0CB", "#FF69B4", "#FF1493", "#C71585"))

# Create a word cloud with the custom pink color palette
wordcloud(words = clean_text_pass$word, freq = clean_text_pass$n, scale = c(3, 0.5),
          random.order = FALSE, colors = pink_palette(length(clean_text_pass$word)))
```

```{r, echo = FALSE, include=FALSE, message = FALSE}
# Clean the text using the functions introduced in lecture
clean_text_fail <- fail %>% 
  select(plot) %>% 
  unnest_tokens(word, plot) %>% 
  mutate(word = str_replace_all(word, "[^[:alnum:]']", "")) %>% 
  filter(!word %in% stop_words$word) %>% 
  filter(!str_detect(word, "^\\d+$")) %>% 
  mutate(word = str_to_lower(word)) %>% 
  count(word, sort = TRUE) %>% 
  slice_head(n = 100)

# Create a Document-Term-Matrix
movie_dtm <- DocumentTermMatrix(fail)

# Define a custom color palette of different shades of blue
blue_palette <- colorRampPalette(c("#E6F3FF", "#BFD6F8", "#99B9F2", "#739DF0"))
```
```{r, echo=FALSE}
# Create a word cloud with the custom blue color palette
wordcloud(words = clean_text_fail$word, freq = clean_text_fail$n, scale = c(3, 0.5),
          random.order = FALSE, colors = blue_palette(length(clean_text_fail$word)))
```

Based on the word clouds, we found that the most common words in the plot of movies that passed the Bechdel test are woman, school, life, girl, family, home, world, love, classic and daughter. Common words in the plot of movies that failed the Bechdel test are life, world, story, save, friends, team, and death.

In the next stage of our analysis, we presented bar graphs displaying the frequency of the top 20 most commonly used words, along with their respective counts, to provide further details about the distribution of these words. Our analysis includes three visual representations: bar graphs for both passed and failed Bechdel Test categories, as well as a pyramid plot that compares the most common words used in movies that passed and failed the Bechdel Test. By presenting these visualizations side by side, we can easily compare and contrast the frequency and type of words used in the plot descriptions of movies that passed and failed the test.


```{r, echo = FALSE, include=FALSE, message = FALSE}
library(ggplot2)
library(ggthemes)

# Create a data frame of the most common words in the plots of movies that passed the Bechdel Test
clean_text <- pass %>% 
  select(plot) %>% 
  unnest_tokens(word, plot) %>% 
  mutate(word = str_replace_all(word, "[^[:alnum:]']", "")) %>% 
  filter(!word %in% stop_words$word) %>% 
  filter(!str_detect(word, "^\\d+$")) %>% 
  mutate(word = str_to_lower(word)) %>% 
  count(word, sort = TRUE) %>% 
  slice_head(n = 20)

```
```{r, echo=FALSE}
# Create a bar graph of the most common words
ggplot(clean_text, aes(x = reorder(word, -n), y = n)) +
  geom_col(fill = "palevioletred") +
  labs(x = "Word", y = "Frequency", title = "Most Common Words in the Plot of Movies \nthat Passed the Bechdel Test") +
  theme_economist() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1, size = 10),
        axis.text.y = element_text(size = 10),
        axis.title = element_text(size = 12),
        plot.title = element_text(size = 14, hjust = 0.5),
        plot.margin = unit(c(1, 1, 1, 1), "cm"),
        panel.background = element_rect(fill = "mistyrose"),
        plot.background = element_rect(fill = "mistyrose"))
```


```{r, echo = FALSE, include=FALSE, message = FALSE}
library(ggplot2)
library(ggthemes)

# Create a data frame of the most common words in the plots of movies that passed the Bechdel Test
clean_text <- fail %>% 
  select(plot) %>% 
  unnest_tokens(word, plot) %>% 
  mutate(word = str_replace_all(word, "[^[:alnum:]']", "")) %>% 
  filter(!word %in% stop_words$word) %>% 
  filter(!str_detect(word, "^\\d+$")) %>% 
  mutate(word = str_to_lower(word)) %>% 
  count(word, sort = TRUE) %>% 
  slice_head(n = 20)
```
```{r, echo=FALSE}
# Create a bar graph of the most common words
ggplot(clean_text, aes(x = reorder(word, -n), y = n)) +
  geom_col(fill = "steelblue") +
  labs(x = "Word", y = "Frequency", title = "Most Common Words in the Plot of Movies \nthat Failed the Bechdel Test") +
  theme_economist() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1, size = 10),
        axis.text.y = element_text(size = 10),
        axis.title = element_text(size = 12),
        plot.title = element_text(size = 14, hjust = 0.5),
        plot.margin = unit(c(1, 1, 1, 1), "cm"))
```

We provide a pyramid plot to show how the words between passing and failed Bechdel test movies differ in frequency. A selection of 20 top words are chosen.

```{r, echo = FALSE, include=FALSE, message = FALSE}
library(dplyr)
library(tidytext)
library(stringr)
library(plotrix)

pass <- data_filtered %>% 
  arrange(desc(binary)) %>% 
  head(500)

fail <- data_filtered %>% 
  arrange(binary) %>% 
  head(500)

# Combine pass and fail into one dataframe
all_bechdel <- bind_rows(pass,fail)

# Clean the 20 words
clean_text <- all_bechdel %>% 
  select(plot) %>% 
  unnest_tokens(word, plot) %>% 
  mutate(word = str_replace_all(word, "[^[:alnum:]']", "")) %>% 
  filter(!word %in% stop_words$word) %>% 
  filter(!str_detect(word, "^\\d+$")) %>% 
  mutate(word = str_to_lower(word)) %>% 
  count(word, sort = TRUE) %>% 
  slice_head(n = 20)

# Create a data frame of the most common words in the plots of movies that passed the Bechdel Test
clean_text_pass <- pass %>% 
  select(plot) %>% 
  unnest_tokens(word, plot) %>% 
  mutate(word = str_replace_all(word, "[^[:alnum:]']", "")) %>% 
  filter(!word %in% stop_words$word) %>% 
  filter(!str_detect(word, "^\\d+$")) %>% 
  mutate(word = str_to_lower(word)) %>% 
  count(word, sort = TRUE) %>% 
  slice_head(n = 20)


# Create a data frame of the most common words in the plots of movies that passed the Bechdel Test
clean_text_fail <- fail %>% 
  select(plot) %>% 
  unnest_tokens(word, plot) %>% 
  mutate(word = str_replace_all(word, "[^[:alnum:]']", "")) %>% 
  filter(!word %in% stop_words$word) %>% 
  filter(!str_detect(word, "^\\d+$")) %>% 
  mutate(word = str_to_lower(word)) %>% 
  count(word, sort = TRUE) %>% 
  slice_head(n = 20)

```
```{r, echo = FALSE, message = FALSE}
# Create the pyramid plot
par(mar=c(5,5,2,2))
pyramid.plot(clean_text_pass$n, clean_text_fail$n,
             labels=clean_text$word, 
             main="Most Common Words from Movie Plot Descriptions",
             lxcol= "palevioletred", rxcol= "steelblue", gap=20,
             top.labels = c("Passed Bechdel Test", " ", "Failed Bechdel Test"),
             xlim=c(0,50),
             laxlab = seq(from = 0, to = 50, by = 10),
             raxlab = seq(from = 0, to = 50, by = 10),
             mtext(" ", side = 1, line = 5, col = "black", cex = 1.2))
```
